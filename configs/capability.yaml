model_cfgs:
  model_name_or_path: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
  inference_backend: vllm
  vllm_init_args:
    tensor_parallel_size: 4
    dtype: bfloat16
    max_model_len: 8192
    gpu_memory_utilization: 0.9
    max_num_seqs: 64
    enable_prefix_caching: true

inference_cfgs:
  sampling_params:
    max_tokens: 16384
    temperature: 0.0
    top_k: 1
    top_p: 1.0
    stop: ["<|endoftext|>"]

cache_cfgs:
  cache_type: json_file
  cache_dir: ./cache/inference
  flush_threshold: 10

eval_cfgs:
  output_dir: ./output
  benchmark_type: capability

  # 公共配置定义
  _common: &common_base

    # 公共judgment配置锚点
    judgment: &common_judgment
      judgment_type: AIME

    # 公共metrics配置锚点
    metrics: &common_metrics
      - metrics_type: Accuracy
        metrics_name: Accuracy
        judgment_cfgs: *common_judgment

  # Benchmarks配置
  benchmarks:
    # Benchmark 1: 完全复用公共metrics配置
    AIME:
      data_cfgs:
        data_path: Maxwell-Jia/AIME_2024
        data_template: AIME
        template_cfgs:
          prompt_builder_name: AIME
        task_list: null
        data_size: null
        load_cfgs:
          split: train
      metrics_cfgs: *common_metrics  # 直接引用公共配置
